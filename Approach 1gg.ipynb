{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "with warnings.catch_warnings():\n",
    "    warnings.filterwarnings(\"ignore\",category=DeprecationWarning)\n",
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "    from sklearn.ensemble import RandomForestRegressor\n",
    "    from sklearn import pipeline, grid_search\n",
    "    from sklearn.base import BaseEstimator, TransformerMixin\n",
    "    from sklearn.pipeline import FeatureUnion\n",
    "    from sklearn.decomposition import TruncatedSVD\n",
    "    from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "    from sklearn.metrics import mean_squared_error, make_scorer\n",
    "    from nltk.stem.porter import *\n",
    "    stemmer = PorterStemmer()\n",
    "    import re\n",
    "    import random\n",
    "    random.seed(2016)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('C:/Users/sneha/Google Drive/Github/DataSet/Kaggle/data/train.csv', encoding=\"ISO-8859-1\")\n",
    "df_test = pd.read_csv('C:/Users/sneha/Google Drive/Github/DataSet/Kaggle/data/test.csv', encoding=\"ISO-8859-1\")\n",
    "df_pro_desc = pd.read_csv('C:/Users/sneha/Google Drive/Github/DataSet/Kaggle/data/product_descriptions.csv')\n",
    "df_attr = pd.read_csv('C:/Users/sneha/Google Drive/Github/DataSet/Kaggle/data/attributes.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating new Dataframes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_brand = df_attr[df_attr.name == \"MFG Brand Name\"][[\"product_uid\", \"value\"]].rename(columns={\"value\": \"brand\"})\n",
    "df_all = pd.concat((df_train, df_test), axis=0, ignore_index=True)\n",
    "df_all = pd.merge(df_all, df_pro_desc, how='left', on='product_uid')\n",
    "df_all = pd.merge(df_all, df_brand, how='left', on='product_uid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_train = df_train.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "strNum = {'zero':0,'one':1,'two':2,'three':3,'four':4,'five':5,'six':6,'seven':7,'eight':8,'nine':9}\n",
    "\n",
    "f = open('spelling.txt','r')\n",
    "zspell = {}\n",
    "for line in f:\n",
    "    a, b = line.strip(\"\\n\").split(\"|\")\n",
    "    zspell[a]=b\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "def text_process(s):\n",
    "    \"\"\"\n",
    "    Takes in a string of text, then performs the following:\n",
    "    1. Clean up data\n",
    "    2. Remove all stopwords\n",
    "    3. Returns a list of the cleaned text  \n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    s = re.sub(r\"(\\w)\\.([A-Z])\", r\"\\1 \\2\", s) #Split words with a.A\n",
    "    s = re.sub(r\"([a-z])([A-Z])\", r\"\\1 \\2\", s) #Split words with a A\n",
    "    s = s.lower()\n",
    "    s = s.replace(\"  \",\" \")\n",
    "    s = re.sub(r\"([0-9])( *),( *)([0-9])\", r\"\\1\\4\", s)\n",
    "    s = s.replace(\",\",\" \")\n",
    "    s = s.replace(\"$\",\" \")\n",
    "    s = s.replace(\"?\",\" \")\n",
    "    s = s.replace(\"-\",\" \")\n",
    "    s = s.replace(\"//\",\"/\")\n",
    "    s = s.replace(\"..\",\".\")\n",
    "    s = s.replace(\" / \",\" \")\n",
    "    s = s.replace(\" \\\\ \",\" \")\n",
    "    s = s.replace(\".\",\" . \")\n",
    "    s = s.replace(\"   \",\" \")\n",
    "    s = s.replace(\"  \",\" \").strip(\" \")\n",
    "    s = re.sub(r\"(.*)\\.$\", r\"\\1\", s) #end period\n",
    "    s = re.sub(r\"(.*)\\/$\", r\"\\1\", s) #end period\n",
    "    s = re.sub(r\"^\\.(.*)\", r\"\\1\", s) #start period\n",
    "    s = re.sub(r\"^\\/(.*)\", r\"\\1\", s) #start slash\n",
    "    s = re.sub(r\"([0-9])([a-z])\", r\"\\1 \\2\", s)\n",
    "    s = re.sub(r\"([a-z])([0-9])\", r\"\\1 \\2\", s)\n",
    "    s = s.replace(\" x \",\" xbi \")\n",
    "    s = re.sub(r\"([a-z])( *)\\.( *)([a-z])\", r\"\\1 \\4\", s)\n",
    "    s = re.sub(r\"([a-z])( *)/( *)([a-z])\", r\"\\1 \\4\", s)\n",
    "    s = s.replace(\"*\",\" xbi \")\n",
    "    s = s.replace(\" by \",\" xbi \")\n",
    "    s = re.sub(r\"([0-9])( *)\\.( *)([0-9])\", r\"\\1.\\4\", s)\n",
    "    s = re.sub(r\"([0-9]+)( *)(inches|inch|in|')\\.?\", r\"\\1in. \", s)\n",
    "    s = re.sub(r\"([0-9]+)( *)(foot|feet|ft|'')\\.?\", r\"\\1ft. \", s)\n",
    "    s = re.sub(r\"([0-9]+)( *)(pounds|pound|lbs|lb)\\.?\", r\"\\1lb. \", s)\n",
    "    s = re.sub(r\"([0-9]+)( *)(square|sq) ?\\.?(feet|foot|ft)\\.?\", r\"\\1sq.ft. \", s)\n",
    "    s = re.sub(r\"([0-9]+)( *)(cubic|cu) ?\\.?(feet|foot|ft)\\.?\", r\"\\1cu.ft. \", s)\n",
    "    s = re.sub(r\"([0-9]+)( *)(gallons|gallon|gal)\\.?\", r\"\\1gal. \", s)\n",
    "    s = re.sub(r\"([0-9]+)( *)(ounces|ounce|oz)\\.?\", r\"\\1oz. \", s)\n",
    "    s = re.sub(r\"([0-9]+)( *)(centimeters|cm)\\.?\", r\"\\1cm. \", s)\n",
    "    s = re.sub(r\"([0-9]+)( *)(milimeters|mm)\\.?\", r\"\\1mm. \", s)\n",
    "    s = re.sub(r\"([0-9]+)( *)(degrees|degree)\\.?\", r\"\\1deg. \", s)\n",
    "    s = s.replace(\" v \",\" volts \")\n",
    "    s = re.sub(r\"([0-9]+)( *)(volts|volt)\\.?\", r\"\\1volt. \", s)\n",
    "    s = re.sub(r\"([0-9]+)( *)(watts|watt)\\.?\", r\"\\1watt. \", s)\n",
    "    s = re.sub(r\"([0-9]+)( *)(amperes|ampere|amps|amp)\\.?\", r\"\\1amp. \", s)\n",
    "    s = s.replace(\"  \",\" \")\n",
    "    s = s.replace(\" . \",\" \")   \n",
    "    s = (\" \").join([z for z in s.split(\" \") if z not in stopwords.words('english')])\n",
    "    s = (\" \").join([str(strNum[z]) if z in strNum else z for z in s.split(\" \")])\n",
    "    s = (\" \").join([stemmer.stem(z) for z in s.split(\" \")])\n",
    "    s = s.lower()\n",
    "    s = (\" \").join([str(zspell[z]) if z in zspell else z for z in s.split(\" \")])\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_all['search_term'] = df_all['search_term'].apply(text_process)\n",
    "df_all['product_title'] = df_all['product_title'].apply(text_process)\n",
    "df_all['product_description'] = df_all['product_description'].apply(text_process)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def text_stem(s):\n",
    "    if isinstance(s, str):\n",
    "        s = s.replace(\",\",\" \")\n",
    "        s = s.replace(\"$\",\" \")\n",
    "        s = s.replace(\"?\",\" \")\n",
    "        s = s.replace(\"-\",\" \")\n",
    "        s = s.replace(\"//\",\"/\")\n",
    "        s = s.replace(\"..\",\".\")\n",
    "        s = s.replace(\" / \",\" \")\n",
    "        s = s.replace(\" \\\\ \",\" \")\n",
    "        s = s.replace(\".\",\" . \")\n",
    "        s = s.replace(\"   \",\" \")\n",
    "        s = s.replace(\"  \",\" \").strip(\" \")\n",
    "        s = (\" \").join([z for z in s.split(\" \") if z not in stopwords.words('english')])\n",
    "        s = (\" \").join([str(strNum[z]) if z in strNum else z for z in s.split(\" \")])\n",
    "        s = (\" \").join([stemmer.stem(z) for z in s.split(\" \")])\n",
    "        s = s.lower()       \n",
    "        return s\n",
    "    else:\n",
    "        return \"null\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "df_all['brand'] = df_all['brand'].map(lambda x:text_stem(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_all.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_all['len_of_query'] = df_all['search_term'].map(lambda x:len(x.split())).astype(np.int64)\n",
    "df_all['len_of_title'] = df_all['product_title'].map(lambda x:len(x.split())).astype(np.int64)\n",
    "df_all['len_of_description'] = df_all['product_description'].map(lambda x:len(x.split())).astype(np.int64)\n",
    "df_all['len_of_brand'] = df_all['brand'].map(lambda x:len(x.split())).astype(np.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def isFloat(string):\n",
    "    try:\n",
    "        float(string)\n",
    "        return True\n",
    "    except ValueError:\n",
    "        return False\n",
    "\n",
    "def eval_f(expr):\n",
    "    first = ''\n",
    "    second = \"\"\n",
    "    flag = 0\n",
    "\n",
    "    if expr.find(\"/\") == 1:    \n",
    "        for a in expr:            \n",
    "            if a == \"/\":\n",
    "                flag = 1\n",
    "                continue\n",
    "            if flag == 0:\n",
    "                first += a\n",
    "            if flag == 1:\n",
    "                second += a\n",
    "        \n",
    "        if (first.isnumeric() == True and  second.isnumeric() == True):\n",
    "            if (float(second)!= 0):\n",
    "                return (float(first)/float(second))\n",
    "            else:\n",
    "                return 1000\n",
    "    else:\n",
    "        if (expr.isnumeric()):\n",
    "            return float(expr)\n",
    "        else:\n",
    "            return 1\n",
    "\n",
    "def multiply_search(exp):\n",
    "    if isFloat(exp):\n",
    "        return 0\n",
    "    a = exp.split()\n",
    "    \n",
    "    prod = 0\n",
    "    for i in range(0,len(a)):\n",
    "        if a[i] == 'xbi':        \n",
    "            \n",
    "            if (i+1 != len(a)):\n",
    "                #print (a[i-1],a[i+1])\n",
    "                try:\n",
    "                    prod = eval_f(re.sub(\"[a-z.]\", \"\",a[i-1])) * eval_f(re.sub(\"[a-z.]\", \"\",a[i+1]))\n",
    "                except Exception as e:\n",
    "                    pass\n",
    "                \n",
    "                a[i] = str(prod)\n",
    "                #print(prod)\n",
    "   \n",
    "    return (\" \".join(a))   \n",
    "\n",
    "def to_float(exp):\n",
    "    if isinstance(exp, str): \n",
    "        s = (\" \").join([str(float(z)) for z in exp.split(\" \") if isFloat(z) ])        \n",
    "        return s\n",
    "def to_str(exp):\n",
    "    if isinstance(exp, str): \n",
    "        s = (\" \").join([z for z in exp.split(\" \") if not isFloat(z) ])\n",
    "        return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_all['search_term'] = df_all['search_term'].apply(multiply_search)\n",
    "df_all['search_term_num'] = df_all['search_term'].apply(to_float)\n",
    "df_all['search_term_str'] = df_all['search_term'].apply(to_str)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_all['product_description'] = df_all['product_description'].apply(multiply_search)\n",
    "df_all['product_description_num'] = df_all['product_description'].apply(to_float)\n",
    "df_all['product_description_str'] = df_all['product_description'].apply(to_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def prod_title_score(description, search_term):    \n",
    "    if isinstance(search_term, str):\n",
    "        \n",
    "        prod_title_list = str(description).split()\n",
    "        total_len = len(search_term.split())\n",
    "        count = 0\n",
    "        for word in search_term.split():\n",
    "            count +=1            \n",
    "        if total_len != 0:\n",
    "            return count\n",
    "        else:\n",
    "            return 0\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_all['prod_desc_score'] = df_all.apply(lambda df_all: prod_title_score(df_all['product_description'],df_all['search_term'] ) ,axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_train.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
