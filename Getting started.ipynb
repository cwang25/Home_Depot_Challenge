{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "#from sklearn import pipeline, model_selection\n",
    "from sklearn import pipeline, grid_search\n",
    "#from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.pipeline import FeatureUnion\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "#from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import mean_squared_error, make_scorer\n",
    "#from nltk.metrics import edit_distance\n",
    "from nltk.stem.porter import *\n",
    "stemmer = PorterStemmer()\n",
    "#from nltk.stem.snowball import SnowballStemmer #0.003 improvement but takes twice as long as PorterStemmer\n",
    "#stemmer = SnowballStemmer('english')\n",
    "import re\n",
    "#import enchant\n",
    "import random\n",
    "random.seed(2016)\n",
    "from autocorrect import spell\n",
    "import enchant\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Step 1: Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "df_train = pd.read_csv('C:/Users/sneha/Google Drive/Github/DataSet/Kaggle/data/train.csv', encoding=\"ISO-8859-1\")\n",
    "df_test = pd.read_csv('C:/Users/sneha/Google Drive/Github/DataSet/Kaggle/data/test.csv', encoding=\"ISO-8859-1\")[:1000] #update here\n",
    "df_pro_desc = pd.read_csv('C:/Users/sneha/Google Drive/Github/DataSet/Kaggle/data/product_descriptions.csv')[:1000] #update here\n",
    "df_attr = pd.read_csv('C:/Users/sneha/Google Drive/Github/DataSet/Kaggle/data/attributes.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Files Loaded: 0.12 minutes ---\n"
     ]
    }
   ],
   "source": [
    "df_brand = df_attr[df_attr.name == \"MFG Brand Name\"][[\"product_uid\", \"value\"]].rename(columns={\"value\": \"brand\"})\n",
    "num_train = df_train.shape[0]\n",
    "df_all = pd.concat((df_train, df_test), axis=0, ignore_index=True)\n",
    "df_all = pd.merge(df_all, df_pro_desc, how='left', on='product_uid')\n",
    "df_all = pd.merge(df_all, df_brand, how='left', on='product_uid')\n",
    "print(\"--- Files Loaded: %s minutes ---\" % round(((time.time() - start_time)/60),2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "f = open('spelling.txt','r')\n",
    "zspell = {}\n",
    "for line in f:\n",
    "    a, b = line.strip(\"\\n\").split(\"|\")\n",
    "    zspell[a]=b\n",
    "f.close()\n",
    "zspell\n",
    "\n",
    "def str_stem(s): \n",
    "    if isinstance(s, str):\n",
    "        s = re.sub(r\"(\\w)\\.([A-Z])\", r\"\\1 \\2\", s) #Split words with a.A\n",
    "        s = s.lower()\n",
    "        s = s.replace(\"  \",\" \")\n",
    "        s = re.sub(r\"([0-9])( *),( *)([0-9])\", r\"\\1\\4\", s)\n",
    "        s = s.replace(\",\",\" \")\n",
    "        s = s.replace(\"$\",\" \")\n",
    "        s = s.replace(\"?\",\" \")\n",
    "        s = s.replace(\"-\",\" \")\n",
    "        s = s.replace(\"//\",\"/\")\n",
    "        s = s.replace(\"..\",\".\")\n",
    "        s = s.replace(\" / \",\" \")\n",
    "        s = s.replace(\" \\\\ \",\" \")\n",
    "        s = s.replace(\".\",\" . \")\n",
    "        s = s.replace(\"   \",\" \")\n",
    "        s = s.replace(\"  \",\" \").strip(\" \")\n",
    "        s = re.sub(r\"(.*)\\.$\", r\"\\1\", s) #end period\n",
    "        s = re.sub(r\"(.*)\\/$\", r\"\\1\", s) #end period\n",
    "        s = re.sub(r\"^\\.(.*)\", r\"\\1\", s) #start period\n",
    "        s = re.sub(r\"^\\/(.*)\", r\"\\1\", s) #start slash\n",
    "        s = re.sub(r\"([0-9])([a-z])\", r\"\\1 \\2\", s)\n",
    "        s = re.sub(r\"([a-z])([0-9])\", r\"\\1 \\2\", s)\n",
    "        s = s.replace(\" x \",\" xbi \")\n",
    "        s = re.sub(r\"([a-z])( *)\\.( *)([a-z])\", r\"\\1 \\4\", s)\n",
    "        s = re.sub(r\"([a-z])( *)/( *)([a-z])\", r\"\\1 \\4\", s)\n",
    "        s = s.replace(\"*\",\" xbi \")\n",
    "        s = s.replace(\" by \",\" xbi \")\n",
    "        s = re.sub(r\"([0-9])( *)\\.( *)([0-9])\", r\"\\1.\\4\", s)\n",
    "        s = re.sub(r\"([0-9]+)( *)(inches|inch|in|')\\.?\", r\"\\1in. \", s)\n",
    "        s = re.sub(r\"([0-9]+)( *)(foot|feet|ft|'')\\.?\", r\"\\1ft. \", s)\n",
    "        s = re.sub(r\"([0-9]+)( *)(pounds|pound|lbs|lb)\\.?\", r\"\\1lb. \", s)\n",
    "        s = re.sub(r\"([0-9]+)( *)(square|sq) ?\\.?(feet|foot|ft)\\.?\", r\"\\1sq.ft. \", s)\n",
    "        s = re.sub(r\"([0-9]+)( *)(cubic|cu) ?\\.?(feet|foot|ft)\\.?\", r\"\\1cu.ft. \", s)\n",
    "        s = re.sub(r\"([0-9]+)( *)(gallons|gallon|gal)\\.?\", r\"\\1gal. \", s)\n",
    "        s = re.sub(r\"([0-9]+)( *)(ounces|ounce|oz)\\.?\", r\"\\1oz. \", s)\n",
    "        s = re.sub(r\"([0-9]+)( *)(centimeters|cm)\\.?\", r\"\\1cm. \", s)\n",
    "        s = re.sub(r\"([0-9]+)( *)(milimeters|mm)\\.?\", r\"\\1mm. \", s)\n",
    "        s = s.replace(\"Â°\",\" degrees \")\n",
    "        s = re.sub(r\"([0-9]+)( *)(degrees|degree)\\.?\", r\"\\1deg. \", s)\n",
    "        s = s.replace(\" v \",\" volts \")\n",
    "        s = re.sub(r\"([0-9]+)( *)(volts|volt)\\.?\", r\"\\1volt. \", s)\n",
    "        s = re.sub(r\"([0-9]+)( *)(watts|watt)\\.?\", r\"\\1watt. \", s)\n",
    "        s = re.sub(r\"([0-9]+)( *)(amperes|ampere|amps|amp)\\.?\", r\"\\1amp. \", s)\n",
    "        s = s.replace(\"  \",\" \")\n",
    "        s = s.replace(\" . \",\" \")\n",
    "        #s = (\" \").join([z for z in s.split(\" \") if z not in stop_w])\n",
    "        s = (\" \").join([str(strNum[z]) if z in strNum else z for z in s.split(\" \")])\n",
    "        s = (\" \").join([stemmer.stem(z) for z in s.split(\" \")])\n",
    "        s = s.lower()\n",
    "        s = (\" \").join([str(zspell[z]) if z in zspell else z for z in s.split(\" \")])\n",
    "        return s\n",
    "    else:\n",
    "        return \"null\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def seg_words(str1, str2):\n",
    "    str2 = str2.lower()\n",
    "    str2 = re.sub(\"[^a-z0-9./]\",\" \", str2)\n",
    "    str2 = [z for z in set(str2.split()) if len(z)>2]\n",
    "    words = str1.lower().split(\" \")\n",
    "    s = []\n",
    "    for word in words:\n",
    "        if len(word)>3:\n",
    "            s1 = []\n",
    "            s1 += segmentit(word,str2,True)\n",
    "            if len(s)>1:\n",
    "                s += [z for z in s1 if z not in ['er','ing','s','less'] and len(z)>1]\n",
    "            else:\n",
    "                s.append(word)\n",
    "        else:\n",
    "            s.append(word)\n",
    "    return (\" \".join(s))\n",
    "\n",
    "def segmentit(s, txt_arr, t):\n",
    "    st = s\n",
    "    r = []\n",
    "    for j in range(len(s)):\n",
    "        for word in txt_arr:\n",
    "            if word == s[:-j]:\n",
    "                r.append(s[:-j])\n",
    "                #print(s[:-j],s[len(s)-j:])\n",
    "                s=s[len(s)-j:]\n",
    "                r += segmentit(s, txt_arr, False)\n",
    "    if t:\n",
    "        i = len((\"\").join(r))\n",
    "        if not i==len(st):\n",
    "            r.append(st[i:])\n",
    "    return r\n",
    "\n",
    "def str_common_word(str1, str2):\n",
    "    words, cnt = str1.split(), 0\n",
    "    for word in words:\n",
    "        if str2.find(word)>=0:\n",
    "            cnt+=1\n",
    "    return cnt\n",
    "\n",
    "def str_whole_word(str1, str2, i_):\n",
    "    cnt = 0\n",
    "    while i_ < len(str2):\n",
    "        i_ = str2.find(str1, i_)\n",
    "        if i_ == -1:\n",
    "            return cnt\n",
    "        else:\n",
    "            cnt += 1\n",
    "            i_ += len(str1)\n",
    "    return cnt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Step 2 : Stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Stemming: 2.15 minutes ---\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "df_all['search_term'] = df_all['search_term'].map(lambda x:str_stem(x))\n",
    "df_all['product_title'] = df_all['product_title'].map(lambda x:str_stem(x))\n",
    "df_all['product_description'] = df_all['product_description'].map(lambda x:str_stem(x))\n",
    "df_all['brand'] = df_all['brand'].map(lambda x:str_stem(x))\n",
    "print(\"--- Stemming: %s minutes ---\" % round(((time.time() - start_time)/60),2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Prod Info: 4.54 minutes ---\n"
     ]
    }
   ],
   "source": [
    "df_all['product_info'] = df_all['search_term']+\"\\t\"+df_all['product_title'] +\"\\t\"+df_all['product_description']\n",
    "print(\"--- Prod Info: %s minutes ---\" % round(((time.time() - start_time)/60),2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_all['len_of_query'] = df_all['search_term'].map(lambda x:len(x.split())).astype(np.int64)\n",
    "df_all['len_of_title'] = df_all['product_title'].map(lambda x:len(x.split())).astype(np.int64)\n",
    "df_all['len_of_description'] = df_all['product_description'].map(lambda x:len(x.split())).astype(np.int64)\n",
    "df_all['len_of_brand'] = df_all['brand'].map(lambda x:len(x.split())).astype(np.int64)\n",
    "df_all['search_term'] = df_all['product_info'].map(lambda x:seg_words(x.split('\\t')[0],x.split('\\t')[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_all['query_in_title'] = df_all['product_info'].map(lambda x:str_whole_word(x.split('\\t')[0],x.split('\\t')[1],0))\n",
    "df_all['query_in_description'] = df_all['product_info'].map(lambda x:str_whole_word(x.split('\\t')[0],x.split('\\t')[2],0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_all['query_last_word_in_title'] = df_all['product_info'].map(lambda x:str_common_word(x.split('\\t')[0].split(\" \")[-1],x.split('\\t')[1]))\n",
    "df_all['query_last_word_in_description'] = df_all['product_info'].map(lambda x:str_common_word(x.split('\\t')[0].split(\" \")[-1],x.split('\\t')[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_all['word_in_title'] = df_all['product_info'].map(lambda x:str_common_word(x.split('\\t')[0],x.split('\\t')[1]))\n",
    "df_all['word_in_description'] = df_all['product_info'].map(lambda x:str_common_word(x.split('\\t')[0],x.split('\\t')[2]))\n",
    "df_all['ratio_title'] = df_all['word_in_title']/df_all['len_of_query']\n",
    "df_all['ratio_description'] = df_all['word_in_description']/df_all['len_of_query']\n",
    "df_all['attr'] = df_all['search_term']+\"\\t\"+df_all['brand']\n",
    "df_all['word_in_brand'] = df_all['attr'].map(lambda x:str_common_word(x.split('\\t')[0],x.split('\\t')[1]))\n",
    "df_all['ratio_brand'] = df_all['word_in_brand']/df_all['len_of_brand']\n",
    "df_brand = pd.unique(df_all.brand.ravel())\n",
    "d={}\n",
    "i = 1000\n",
    "for s in df_brand:\n",
    "    d[s]=i\n",
    "    i+=3\n",
    "df_all['brand_feature'] = df_all['brand'].map(lambda x:d[x])\n",
    "df_all['search_term_feature'] = df_all['search_term'].map(lambda x:len(x))\n",
    "df_all.to_csv('df_all.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Not only do angles make joints stronger, they also provide more consistent, straight corners. Simpson Strong-Tie offers a wide variety of angles in various sizes and thicknesses to handle light-duty jobs or projects where a structural connection is needed. Some can be bent (skewed) to match the project. For outdoor projects or those where moisture is present, use our ZMAX zinc-coated connectors, which provide extra resistance against corrosion (look for a \"Z\" at the end of the model number).Versatile connector for various 90 connections and home repair projectsStronger than angled nailing or screw fastening aloneHelp ensure joints are consistently straight and strongDimensions: 3 in. x 3 in. x 1-1/2 in.Made from 12-Gauge steelGalvanized for extra corrosion resistanceInstall with 10d common nails or #9 x 1-1/2 in. Strong-Drive SD screws'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all['product_description'][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'not onli do angl make joint stronger they also provid more consist straight corner simpson strong tie offer a wide varieti of angl in variou size and thick to handl light duti job or project where a structur connect is need some can be bent (skewed) to match the project for outdoor project or those where moistur is present use our zmax zinc coat connector which provid extra resist against corros (look for a \"z\" at the end of the model number) versatil connector for variou 90 connect and home repair project stronger than angl nail or screw fasten alon help ensur joint are consist straight and strong dimensions: 3in. xbi 3in. xbi 1 1/2in. made from 12 gaug steel galvan for extra corros resist instal with 10 d common nail or #9 xbi 1 1/2in. strong drive sd screw'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all['product_description'][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'l bracket'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all['search_term'][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'l bracket\\tsimpson strong tie 12 gaug angl\\tnot onli do angl make joint stronger they also provid more consist straight corner simpson strong tie offer a wide varieti of angl in variou size and thick to handl light duti job or project where a structur connect is need some can be bent (skewed) to match the project for outdoor project or those where moistur is present use our zmax zinc coat connector which provid extra resist against corros (look for a \"z\" at the end of the model number) versatil connector for variou 90 connect and home repair project stronger than angl nail or screw fasten alon help ensur joint are consist straight and strong dimensions: 3in. xbi 3in. xbi 1 1/2in. made from 12 gaug steel galvan for extra corros resist instal with 10 d common nail or #9 xbi 1 1/2in. strong drive sd screw'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xyz[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Stemming: 6.76 minutes ---\n",
      "--- Prod Info: 6.76 minutes ---\n",
      "--- Len of: 6.77 minutes ---\n",
      "--- Query In: 6.86 minutes ---\n",
      "--- Query Last Word In: 6.88 minutes ---\n",
      "--- Features Set: 6.98 minutes ---\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Valley View Industries Metal Stakes (4-Pack) are 9 in. galvanized steel stakes for use with all Valley View lawn edgings and brick and paver edgings. These utility stakes can also be used for many other purposes. It is recommended that anchor stakes are used every five feet on designs that have the edging in straight lengths. Where there are curved designs for edgings, additional anchor stakes are recommended at the curve points. Anchor stakes should be staked in at a 45 degree angle. Gloves and eye protection are recommended.Can be used with all valley View lawn edgings and brick/ paver edgingsUtility stakes can be used for many purposesGalvanized steel for strength9 in. lengthPriced competitively yet provides much more value in product'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pro_desc['product_description'][9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'valley view industries metal stakes (4 pack) are 9 in galvanized steel stakes for use with all valley view lawn edgings and brick and paver edgings these utility stakes can also be used for many other purposes it is recommended that anchor stakes are used every five feet on designs that have the edging in straight lengths where there are curved designs for edgings additional anchor stakes are recommended at the curve points anchor stakes should be staked in at a 45 degree angle gloves and eye protection are recommended can be used with all valley view lawn edgings and brick paver edgings utility stakes can be used for many purposes galvanized steel for strength 9 in length priced competitively yet provides much more value in product'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pro_desc['product_description'][9]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### PART 2: Feature Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import time\n",
    "start_time = time.time()\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from nltk.metrics import edit_distance\n",
    "import re\n",
    "\n",
    "def str_common_word(str1, str2):\n",
    "    str2 = str2.lower().split(\" \")\n",
    "    if str1 in str2:\n",
    "        cnt=1\n",
    "    else:\n",
    "        cnt=0\n",
    "    return cnt\n",
    "\n",
    "def str_common_word2(str1, str2):\n",
    "    str2 = str(str2).lower()\n",
    "    if str2.find(str1)>=0:\n",
    "        cnt=1\n",
    "    else:\n",
    "        cnt=0\n",
    "    return cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "df_train = pd.read_csv('C:/Users/sneha/Google Drive/Github/DataSet/Kaggle/data/train.csv', encoding=\"ISO-8859-1\")\n",
    "df_test = pd.read_csv('C:/Users/sneha/Google Drive/Github/DataSet/Kaggle/data/test.csv', encoding=\"ISO-8859-1\")#update here\n",
    "df_all = pd.concat((df_train, df_test), axis=0, ignore_index=True)\n",
    "df_all = df_all[['product_uid','search_term','product_title']]\n",
    "df_all.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>product_uid</th>\n",
       "      <th>search_term</th>\n",
       "      <th>product_title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>100001</td>\n",
       "      <td>angle bracket</td>\n",
       "      <td>Simpson Strong-Tie 12-Gauge Angle</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>100001</td>\n",
       "      <td>l bracket</td>\n",
       "      <td>Simpson Strong-Tie 12-Gauge Angle</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>100002</td>\n",
       "      <td>deck over</td>\n",
       "      <td>BEHR Premium Textured DeckOver 1-gal. #SC-141 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>100005</td>\n",
       "      <td>rain shower head</td>\n",
       "      <td>Delta Vero 1-Handle Shower Only Faucet Trim Ki...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>100005</td>\n",
       "      <td>shower only faucet</td>\n",
       "      <td>Delta Vero 1-Handle Shower Only Faucet Trim Ki...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index  product_uid         search_term  \\\n",
       "0      0       100001       angle bracket   \n",
       "1      1       100001           l bracket   \n",
       "2      2       100002           deck over   \n",
       "3      3       100005    rain shower head   \n",
       "4      4       100005  shower only faucet   \n",
       "\n",
       "                                       product_title  \n",
       "0                  Simpson Strong-Tie 12-Gauge Angle  \n",
       "1                  Simpson Strong-Tie 12-Gauge Angle  \n",
       "2  BEHR Premium Textured DeckOver 1-gal. #SC-141 ...  \n",
       "3  Delta Vero 1-Handle Shower Only Faucet Trim Ki...  \n",
       "4  Delta Vero 1-Handle Shower Only Faucet Trim Ki...  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_prod = pd.read_csv('C:/Users/sneha/Google Drive/Github/DataSet/Kaggle/data/product_descriptions.csv').fillna(\" \") #update here\n",
    "df_attr = pd.read_csv('C:/Users/sneha/Google Drive/Github/DataSet/Kaggle/data/attributes.csv').fillna(\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "d_prod_query = {}\n",
    "for i in range(len(df_all)):\n",
    "    b_ = str(df_all['product_uid'][i])\n",
    "    if b_ not in d_prod_query:\n",
    "        d_prod_query[b_] = [list(set(str(df_all['search_term'][i]).lower().split(\" \"))), \n",
    "                            str(df_all['product_title'][i]).lower(),\n",
    "                            str(df_prod.loc[df_prod['product_uid'] == df_all['product_uid'][i]]['product_description'].iloc[0]).lower()]\n",
    "    else:\n",
    "        d_prod_query[b_][0] = list(set(d_prod_query[b_][0] + list(set(str(df_all['search_term'][i]).lower().split(\" \")))))\n",
    "\n",
    "f = open(\"dict.txt\", \"w\")\n",
    "f.write(str(d_prod_query))\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
