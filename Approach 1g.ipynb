{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sneha\\Anaconda324\\lib\\site-packages\\sklearn\\utils\\fixes.py:64: DeprecationWarning: inspect.getargspec() is deprecated, use inspect.signature() instead\n",
      "  if 'order' in inspect.getargspec(np.copy)[0]:\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "\n",
    "with warnings.catch_warnings():\n",
    "    warnings.filterwarnings(\"ignore\",category=DeprecationWarning)\n",
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "    from sklearn.ensemble import RandomForestRegressor\n",
    "    from sklearn import pipeline, grid_search\n",
    "    from sklearn.base import BaseEstimator, TransformerMixin\n",
    "    from sklearn.pipeline import FeatureUnion\n",
    "    from sklearn.decomposition import TruncatedSVD\n",
    "    from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "    from sklearn.metrics import mean_squared_error, make_scorer\n",
    "    from nltk.stem.porter import *\n",
    "    stemmer = PorterStemmer()\n",
    "    import re\n",
    "    import random\n",
    "    random.seed(2016)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('C:/Users/sneha/Google Drive/Github/DataSet/Kaggle/data/train.csv', encoding=\"ISO-8859-1\")\n",
    "df_test = pd.read_csv('C:/Users/sneha/Google Drive/Github/DataSet/Kaggle/data/test.csv', encoding=\"ISO-8859-1\")\n",
    "df_pro_desc = pd.read_csv('C:/Users/sneha/Google Drive/Github/DataSet/Kaggle/data/product_descriptions.csv')\n",
    "df_attr = pd.read_csv('C:/Users/sneha/Google Drive/Github/DataSet/Kaggle/data/attributes.csv')\n",
    "df_brand = df_attr[df_attr.name == \"MFG Brand Name\"][[\"product_uid\", \"value\"]].rename(columns={\"value\": \"brand\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_train = pd.read_excel('pre_processed_data\\df_train.xlsx')\n",
    "df_test = pd.read_excel('pre_processed_data\\df_test.xlsx')\n",
    "df_prod = pd.read_excel('pre_processed_data\\df_prod.xlsx')\n",
    "df_brand = pd.read_excel('pre_processed_data\\df_brand.xlsx')\n",
    "df_attr = pd.read_excel('pre_processed_data\\df_attr.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating new Dataframes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "df_all = pd.concat((df_train, df_test), axis=0, ignore_index=True)\n",
    "df_all = pd.merge(df_all, df_prod, how='left', on='product_uid')\n",
    "df_all = pd.merge(df_all, df_brand, how='left', on='product_uid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_train = df_train.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>product_title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>simpson strong tie 12 gaug angl</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                    product_title\n",
       "0   2  simpson strong tie 12 gaug angl"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "df_train2 = df_train[['id','product_title']]\n",
    "df_train2.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_all = pd.merge(df_all, df_train2, how='left', on='id')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "strNum = {'zero':0,'one':1,'two':2,'three':3,'four':4,'five':5,'six':6,'seven':7,'eight':8,'nine':9}\n",
    "\n",
    "f = open('spelling.txt','r')\n",
    "zspell = {}\n",
    "for line in f:\n",
    "    a, b = line.strip(\"\\n\").split(\"|\")\n",
    "    zspell[a]=b\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "def text_process(s):\n",
    "    \"\"\"\n",
    "    Takes in a string of text, then performs the following:\n",
    "    1. Clean up data\n",
    "    2. Remove all stopwords\n",
    "    3. Returns a list of the cleaned text  \n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    s = re.sub(r\"(\\w)\\.([A-Z])\", r\"\\1 \\2\", s) #Split words with a.A\n",
    "    s = re.sub(r\"([a-z])([A-Z])\", r\"\\1 \\2\", s) #Split words with a A\n",
    "    s = s.lower()\n",
    "    s = s.replace(\"  \",\" \")\n",
    "    s = re.sub(r\"([0-9])( *),( *)([0-9])\", r\"\\1\\4\", s)\n",
    "    s = s.replace(\",\",\" \")\n",
    "    s = s.replace(\"$\",\" \")\n",
    "    s = s.replace(\"?\",\" \")\n",
    "    s = s.replace(\"-\",\" \")\n",
    "    s = s.replace(\"//\",\"/\")\n",
    "    s = s.replace(\"..\",\".\")\n",
    "    s = s.replace(\" / \",\" \")\n",
    "    s = s.replace(\" \\\\ \",\" \")\n",
    "    s = s.replace(\".\",\" . \")\n",
    "    s = s.replace(\"   \",\" \")\n",
    "    s = s.replace(\"  \",\" \").strip(\" \")\n",
    "    s = re.sub(r\"(.*)\\.$\", r\"\\1\", s) #end period\n",
    "    s = re.sub(r\"(.*)\\/$\", r\"\\1\", s) #end period\n",
    "    s = re.sub(r\"^\\.(.*)\", r\"\\1\", s) #start period\n",
    "    s = re.sub(r\"^\\/(.*)\", r\"\\1\", s) #start slash\n",
    "    s = re.sub(r\"([0-9])([a-z])\", r\"\\1 \\2\", s)\n",
    "    s = re.sub(r\"([a-z])([0-9])\", r\"\\1 \\2\", s)\n",
    "    s = s.replace(\" x \",\" xbi \")\n",
    "    s = re.sub(r\"([a-z])( *)\\.( *)([a-z])\", r\"\\1 \\4\", s)\n",
    "    s = re.sub(r\"([a-z])( *)/( *)([a-z])\", r\"\\1 \\4\", s)\n",
    "    s = s.replace(\"*\",\" xbi \")\n",
    "    s = s.replace(\" by \",\" xbi \")\n",
    "    s = re.sub(r\"([0-9])( *)\\.( *)([0-9])\", r\"\\1.\\4\", s)\n",
    "    s = re.sub(r\"([0-9]+)( *)(inches|inch|in|')\\.?\", r\"\\1in. \", s)\n",
    "    s = re.sub(r\"([0-9]+)( *)(foot|feet|ft|'')\\.?\", r\"\\1ft. \", s)\n",
    "    s = re.sub(r\"([0-9]+)( *)(pounds|pound|lbs|lb)\\.?\", r\"\\1lb. \", s)\n",
    "    s = re.sub(r\"([0-9]+)( *)(square|sq) ?\\.?(feet|foot|ft)\\.?\", r\"\\1sq.ft. \", s)\n",
    "    s = re.sub(r\"([0-9]+)( *)(cubic|cu) ?\\.?(feet|foot|ft)\\.?\", r\"\\1cu.ft. \", s)\n",
    "    s = re.sub(r\"([0-9]+)( *)(gallons|gallon|gal)\\.?\", r\"\\1gal. \", s)\n",
    "    s = re.sub(r\"([0-9]+)( *)(ounces|ounce|oz)\\.?\", r\"\\1oz. \", s)\n",
    "    s = re.sub(r\"([0-9]+)( *)(centimeters|cm)\\.?\", r\"\\1cm. \", s)\n",
    "    s = re.sub(r\"([0-9]+)( *)(milimeters|mm)\\.?\", r\"\\1mm. \", s)\n",
    "    s = re.sub(r\"([0-9]+)( *)(degrees|degree)\\.?\", r\"\\1deg. \", s)\n",
    "    s = s.replace(\" v \",\" volts \")\n",
    "    s = re.sub(r\"([0-9]+)( *)(volts|volt)\\.?\", r\"\\1volt. \", s)\n",
    "    s = re.sub(r\"([0-9]+)( *)(watts|watt)\\.?\", r\"\\1watt. \", s)\n",
    "    s = re.sub(r\"([0-9]+)( *)(amperes|ampere|amps|amp)\\.?\", r\"\\1amp. \", s)\n",
    "    s = s.replace(\"  \",\" \")\n",
    "    s = s.replace(\" . \",\" \")   \n",
    "    s = (\" \").join([z for z in s.split(\" \") if z not in stopwords.words('english')])\n",
    "    s = (\" \").join([str(strNum[z]) if z in strNum else z for z in s.split(\" \")])\n",
    "    s = (\" \").join([stemmer.stem(z) for z in s.split(\" \")])\n",
    "    s = s.lower()\n",
    "    s = (\" \").join([str(zspell[z]) if z in zspell else z for z in s.split(\" \")])\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_all['search_term'] = df_all['search_term'].apply(text_process)\n",
    "df_all['product_title'] = df_all['product_title'].apply(text_process)\n",
    "df_all['product_description'] = df_all['product_description'].apply(text_process)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def text_stem(s):\n",
    "    if isinstance(s, str):\n",
    "        s = s.replace(\",\",\" \")\n",
    "        s = s.replace(\"$\",\" \")\n",
    "        s = s.replace(\"?\",\" \")\n",
    "        s = s.replace(\"-\",\" \")\n",
    "        s = s.replace(\"//\",\"/\")\n",
    "        s = s.replace(\"..\",\".\")\n",
    "        s = s.replace(\" / \",\" \")\n",
    "        s = s.replace(\" \\\\ \",\" \")\n",
    "        s = s.replace(\".\",\" . \")\n",
    "        s = s.replace(\"   \",\" \")\n",
    "        s = s.replace(\"  \",\" \").strip(\" \")\n",
    "        s = (\" \").join([z for z in s.split(\" \") if z not in stopwords.words('english')])\n",
    "        s = (\" \").join([str(strNum[z]) if z in strNum else z for z in s.split(\" \")])\n",
    "        s = (\" \").join([stemmer.stem(z) for z in s.split(\" \")])\n",
    "        s = s.lower()       \n",
    "        return s\n",
    "    else:\n",
    "        return \"null\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "df_all['brand'] = df_all['brand'].map(lambda x:text_stem(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>product_title</th>\n",
       "      <th>product_title_str</th>\n",
       "      <th>product_uid</th>\n",
       "      <th>relevance</th>\n",
       "      <th>search_term</th>\n",
       "      <th>search_term_num</th>\n",
       "      <th>search_term_str</th>\n",
       "      <th>product_description</th>\n",
       "      <th>product_description_num</th>\n",
       "      <th>product_description_str</th>\n",
       "      <th>brand</th>\n",
       "      <th>len_of_query</th>\n",
       "      <th>len_of_title</th>\n",
       "      <th>len_of_description</th>\n",
       "      <th>len_of_brand</th>\n",
       "      <th>prod_desc_score</th>\n",
       "      <th>prod_desc_score_str</th>\n",
       "      <th>prod_desc_score_num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>100001</td>\n",
       "      <td>3.00</td>\n",
       "      <td>angl bracket</td>\n",
       "      <td>NaN</td>\n",
       "      <td>angl bracket</td>\n",
       "      <td>angl make joint stronger also provid consist s...</td>\n",
       "      <td>90.0 9.0 3.0 1.0 12.0 10.0 1.0 1.0</td>\n",
       "      <td>angl make joint stronger also provid consist s...</td>\n",
       "      <td>simpson strong-ti</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>96</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>100001</td>\n",
       "      <td>2.50</td>\n",
       "      <td>l bracket</td>\n",
       "      <td>NaN</td>\n",
       "      <td>l bracket</td>\n",
       "      <td>angl make joint stronger also provid consist s...</td>\n",
       "      <td>90.0 9.0 3.0 1.0 12.0 10.0 1.0 1.0</td>\n",
       "      <td>angl make joint stronger also provid consist s...</td>\n",
       "      <td>simpson strong-ti</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>96</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>100002</td>\n",
       "      <td>3.00</td>\n",
       "      <td>deck</td>\n",
       "      <td>NaN</td>\n",
       "      <td>deck</td>\n",
       "      <td>behr premium textur deckov innov solid color c...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>behr premium textur deckov innov solid color c...</td>\n",
       "      <td>behr premium textur deckov</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>124</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>100005</td>\n",
       "      <td>2.33</td>\n",
       "      <td>rain shower head</td>\n",
       "      <td>NaN</td>\n",
       "      <td>rain shower head</td>\n",
       "      <td>updat bathroom delta vero singl handl shower f...</td>\n",
       "      <td>3.0 10000.0</td>\n",
       "      <td>updat bathroom delta vero singl handl shower f...</td>\n",
       "      <td>delta</td>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "      <td>77</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>100005</td>\n",
       "      <td>2.67</td>\n",
       "      <td>shower faucet</td>\n",
       "      <td>NaN</td>\n",
       "      <td>shower faucet</td>\n",
       "      <td>updat bathroom delta vero singl handl shower f...</td>\n",
       "      <td>3.0 10000.0</td>\n",
       "      <td>updat bathroom delta vero singl handl shower f...</td>\n",
       "      <td>delta</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>77</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  product_title  product_title_str  product_uid  relevance  \\\n",
       "0   2              0                  0       100001       3.00   \n",
       "1   3              0                  0       100001       2.50   \n",
       "2   9              0                  0       100002       3.00   \n",
       "3  16              0                  0       100005       2.33   \n",
       "4  17              0                  0       100005       2.67   \n",
       "\n",
       "        search_term search_term_num   search_term_str  \\\n",
       "0      angl bracket             NaN      angl bracket   \n",
       "1         l bracket             NaN         l bracket   \n",
       "2              deck             NaN              deck   \n",
       "3  rain shower head             NaN  rain shower head   \n",
       "4     shower faucet             NaN     shower faucet   \n",
       "\n",
       "                                 product_description  \\\n",
       "0  angl make joint stronger also provid consist s...   \n",
       "1  angl make joint stronger also provid consist s...   \n",
       "2  behr premium textur deckov innov solid color c...   \n",
       "3  updat bathroom delta vero singl handl shower f...   \n",
       "4  updat bathroom delta vero singl handl shower f...   \n",
       "\n",
       "              product_description_num  \\\n",
       "0  90.0 9.0 3.0 1.0 12.0 10.0 1.0 1.0   \n",
       "1  90.0 9.0 3.0 1.0 12.0 10.0 1.0 1.0   \n",
       "2                                 2.0   \n",
       "3                         3.0 10000.0   \n",
       "4                         3.0 10000.0   \n",
       "\n",
       "                             product_description_str  \\\n",
       "0  angl make joint stronger also provid consist s...   \n",
       "1  angl make joint stronger also provid consist s...   \n",
       "2  behr premium textur deckov innov solid color c...   \n",
       "3  updat bathroom delta vero singl handl shower f...   \n",
       "4  updat bathroom delta vero singl handl shower f...   \n",
       "\n",
       "                        brand  len_of_query  len_of_title  len_of_description  \\\n",
       "0           simpson strong-ti             2             6                  96   \n",
       "1           simpson strong-ti             2             6                  96   \n",
       "2  behr premium textur deckov             1            11                 124   \n",
       "3                       delta             3            11                  77   \n",
       "4                       delta             2            11                  77   \n",
       "\n",
       "   len_of_brand  prod_desc_score  prod_desc_score_str  prod_desc_score_num  \n",
       "0             2                3                    3                    0  \n",
       "1             2                0                    0                    0  \n",
       "2             4                3                    3                    0  \n",
       "3             1                1                    1                    0  \n",
       "4             1                2                    2                    0  "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all = df_all.drop(['product_titlee_num'], axis = 1)\n",
    "df_all.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_all['len_of_query'] = df_all['search_term'].map(lambda x:len(str(x).split())).astype(np.int64)\n",
    "df_all['len_of_title'] = df_all['product_title'].map(lambda x:len(x.split())).astype(np.int64)\n",
    "df_all['len_of_description'] = df_all['product_description'].map(lambda x:len(x.split())).astype(np.int64)\n",
    "df_all['len_of_brand'] = df_all['brand'].map(lambda x:len(str(x).split())).astype(np.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def isFloat(string):\n",
    "    try:\n",
    "        float(string)\n",
    "        return True\n",
    "    except ValueError:\n",
    "        return False\n",
    "\n",
    "def eval_f(expr):\n",
    "    first = ''\n",
    "    second = \"\"\n",
    "    flag = 0\n",
    "\n",
    "    if expr.find(\"/\") == 1:    \n",
    "        for a in expr:            \n",
    "            if a == \"/\":\n",
    "                flag = 1\n",
    "                continue\n",
    "            if flag == 0:\n",
    "                first += a\n",
    "            if flag == 1:\n",
    "                second += a\n",
    "        \n",
    "        if (first.isnumeric() == True and  second.isnumeric() == True):\n",
    "            if (float(second)!= 0):\n",
    "                return (float(first)/float(second))\n",
    "            else:\n",
    "                return 1000\n",
    "    else:\n",
    "        if (expr.isnumeric()):\n",
    "            return float(expr)\n",
    "        else:\n",
    "            return 1\n",
    "\n",
    "def multiply_search(exp):\n",
    "    if isFloat(exp):\n",
    "        return 0\n",
    "    a = exp.split()\n",
    "    \n",
    "    prod = 0\n",
    "    for i in range(0,len(a)):\n",
    "        if a[i] == 'xbi':        \n",
    "            \n",
    "            if (i+1 != len(a)):\n",
    "                #print (a[i-1],a[i+1])\n",
    "                try:\n",
    "                    prod = eval_f(re.sub(\"[a-z.]\", \"\",a[i-1])) * eval_f(re.sub(\"[a-z.]\", \"\",a[i+1]))\n",
    "                except Exception as e:\n",
    "                    pass\n",
    "                \n",
    "                a[i] = str(prod)\n",
    "                #print(prod)\n",
    "   \n",
    "    return (\" \".join(a))   \n",
    "\n",
    "def to_float(exp):\n",
    "    if isinstance(exp, str): \n",
    "        s = (\" \").join([str(float(z)) for z in exp.split(\" \") if isFloat(z) ])        \n",
    "        return s\n",
    "def to_str(exp):\n",
    "    if isinstance(exp, str): \n",
    "        s = (\" \").join([z for z in exp.split(\" \") if not isFloat(z) ])\n",
    "        return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_all['search_term'] = df_all['search_term'].apply(multiply_search)\n",
    "df_all['search_term_num'] = df_all['search_term'].apply(to_float)\n",
    "df_all['search_term_str'] = df_all['search_term'].apply(to_str)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_all['product_description'] = df_all['product_description'].apply(multiply_search)\n",
    "df_all['product_description_num'] = df_all['product_description'].apply(to_float)\n",
    "df_all['product_description_str'] = df_all['product_description'].apply(to_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def prod_title_score(description, search_term):    \n",
    "        \n",
    "    prod_title_list = str(description).split()\n",
    "    total_len = len(str(search_term).split())\n",
    "    count = 0\n",
    "    for word in str(search_term).split():\n",
    "        count += prod_title_list.count(word)            \n",
    "\n",
    "    return count\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_all['prod_desc_score'] = df_all.apply(lambda df_all: prod_title_score(df_all['product_description'],df_all['search_term'] ) ,axis = 1)\n",
    "df_all['prod_desc_score_str'] = df_all.apply(lambda df_all: prod_title_score(df_all['product_description_str'],df_all['search_term_str'] ) ,axis = 1)\n",
    "df_all['prod_desc_score_num'] = df_all.apply(lambda df_all: prod_title_score(df_all['product_description_num'],df_all['search_term_num'] ) ,axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_all['product_title_score'] = df_all.apply(lambda df_all: prod_title_score(df_all['product_title'],df_all['search_term'] ) ,axis = 1)\n",
    "df_all['product_title_str'] = df_all.apply(lambda df_all: prod_title_score(df_all['product_title_str'],df_all['search_term_str'] ) ,axis = 1)\n",
    "#df_all['product_title_num'] = df_all.apply(lambda df_all: prod_title_score(df_all['product_title_num'],df_all['search_term_num'] ) ,axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>product_title</th>\n",
       "      <th>product_title_str</th>\n",
       "      <th>product_uid</th>\n",
       "      <th>relevance</th>\n",
       "      <th>search_term</th>\n",
       "      <th>search_term_num</th>\n",
       "      <th>search_term_str</th>\n",
       "      <th>product_description</th>\n",
       "      <th>product_description_num</th>\n",
       "      <th>product_description_str</th>\n",
       "      <th>brand</th>\n",
       "      <th>len_of_query</th>\n",
       "      <th>len_of_title</th>\n",
       "      <th>len_of_description</th>\n",
       "      <th>len_of_brand</th>\n",
       "      <th>prod_desc_score</th>\n",
       "      <th>prod_desc_score_str</th>\n",
       "      <th>prod_desc_score_num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>100001</td>\n",
       "      <td>3.00</td>\n",
       "      <td>angl bracket</td>\n",
       "      <td>NaN</td>\n",
       "      <td>angl bracket</td>\n",
       "      <td>angl make joint stronger also provid consist s...</td>\n",
       "      <td>90.0 9.0 3.0 1.0 12.0 10.0 1.0 1.0</td>\n",
       "      <td>angl make joint stronger also provid consist s...</td>\n",
       "      <td>simpson strong-ti</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>96</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>100001</td>\n",
       "      <td>2.50</td>\n",
       "      <td>l bracket</td>\n",
       "      <td>NaN</td>\n",
       "      <td>l bracket</td>\n",
       "      <td>angl make joint stronger also provid consist s...</td>\n",
       "      <td>90.0 9.0 3.0 1.0 12.0 10.0 1.0 1.0</td>\n",
       "      <td>angl make joint stronger also provid consist s...</td>\n",
       "      <td>simpson strong-ti</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>96</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>100002</td>\n",
       "      <td>3.00</td>\n",
       "      <td>deck</td>\n",
       "      <td>NaN</td>\n",
       "      <td>deck</td>\n",
       "      <td>behr premium textur deckov innov solid color c...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>behr premium textur deckov innov solid color c...</td>\n",
       "      <td>behr premium textur deckov</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>124</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>100005</td>\n",
       "      <td>2.33</td>\n",
       "      <td>rain shower head</td>\n",
       "      <td>NaN</td>\n",
       "      <td>rain shower head</td>\n",
       "      <td>updat bathroom delta vero singl handl shower f...</td>\n",
       "      <td>3.0 10000.0</td>\n",
       "      <td>updat bathroom delta vero singl handl shower f...</td>\n",
       "      <td>delta</td>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "      <td>77</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>100005</td>\n",
       "      <td>2.67</td>\n",
       "      <td>shower faucet</td>\n",
       "      <td>NaN</td>\n",
       "      <td>shower faucet</td>\n",
       "      <td>updat bathroom delta vero singl handl shower f...</td>\n",
       "      <td>3.0 10000.0</td>\n",
       "      <td>updat bathroom delta vero singl handl shower f...</td>\n",
       "      <td>delta</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>77</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  product_title  product_title_str  product_uid  relevance  \\\n",
       "0   2              0                  0       100001       3.00   \n",
       "1   3              0                  0       100001       2.50   \n",
       "2   9              0                  0       100002       3.00   \n",
       "3  16              0                  0       100005       2.33   \n",
       "4  17              0                  0       100005       2.67   \n",
       "\n",
       "        search_term search_term_num   search_term_str  \\\n",
       "0      angl bracket             NaN      angl bracket   \n",
       "1         l bracket             NaN         l bracket   \n",
       "2              deck             NaN              deck   \n",
       "3  rain shower head             NaN  rain shower head   \n",
       "4     shower faucet             NaN     shower faucet   \n",
       "\n",
       "                                 product_description  \\\n",
       "0  angl make joint stronger also provid consist s...   \n",
       "1  angl make joint stronger also provid consist s...   \n",
       "2  behr premium textur deckov innov solid color c...   \n",
       "3  updat bathroom delta vero singl handl shower f...   \n",
       "4  updat bathroom delta vero singl handl shower f...   \n",
       "\n",
       "              product_description_num  \\\n",
       "0  90.0 9.0 3.0 1.0 12.0 10.0 1.0 1.0   \n",
       "1  90.0 9.0 3.0 1.0 12.0 10.0 1.0 1.0   \n",
       "2                                 2.0   \n",
       "3                         3.0 10000.0   \n",
       "4                         3.0 10000.0   \n",
       "\n",
       "                             product_description_str  \\\n",
       "0  angl make joint stronger also provid consist s...   \n",
       "1  angl make joint stronger also provid consist s...   \n",
       "2  behr premium textur deckov innov solid color c...   \n",
       "3  updat bathroom delta vero singl handl shower f...   \n",
       "4  updat bathroom delta vero singl handl shower f...   \n",
       "\n",
       "                        brand  len_of_query  len_of_title  len_of_description  \\\n",
       "0           simpson strong-ti             2             6                  96   \n",
       "1           simpson strong-ti             2             6                  96   \n",
       "2  behr premium textur deckov             1            11                 124   \n",
       "3                       delta             3            11                  77   \n",
       "4                       delta             2            11                  77   \n",
       "\n",
       "   len_of_brand  prod_desc_score  prod_desc_score_str  prod_desc_score_num  \n",
       "0             2                3                    3                    0  \n",
       "1             2                0                    0                    0  \n",
       "2             4                3                    3                    0  \n",
       "3             1                1                    1                    0  \n",
       "4             1                2                    2                    0  "
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def seg_words(str1, str2):\n",
    "    str2 = str2.lower()\n",
    "    str2 = re.sub(\"[^a-z0-9./]\",\" \", str2)\n",
    "    str2 = [z for z in set(str2.split()) if len(z)>2]\n",
    "    words = str1.lower().split(\" \")\n",
    "    s = []\n",
    "    for word in words:\n",
    "        if len(word)>3:\n",
    "            s1 = []\n",
    "            s1 += segmentit(word,str2,True)\n",
    "            if len(s)>1:\n",
    "                s += [z for z in s1 if z not in ['er','ing','s','less'] and len(z)>1]\n",
    "            else:\n",
    "                s.append(word)\n",
    "        else:\n",
    "            s.append(word)\n",
    "    return (\" \".join(s))\n",
    "def segmentit(s, txt_arr, t):\n",
    "    st = s\n",
    "    r = []\n",
    "    for j in range(len(s)):\n",
    "        for word in txt_arr:\n",
    "            if word == s[:-j]:\n",
    "                r.append(s[:-j])\n",
    "                #print(s[:-j],s[len(s)-j:])\n",
    "                s=s[len(s)-j:]\n",
    "                r += segmentit(s, txt_arr, False)\n",
    "    if t:\n",
    "        i = len((\"\").join(r))\n",
    "        if not i==len(st):\n",
    "            r.append(st[i:])\n",
    "    return r\n",
    "\n",
    "def str_common_word(str1, str2):\n",
    "    words, cnt = str1.split(), 0\n",
    "    for word in words:\n",
    "        if str2.find(word)>=0:\n",
    "            cnt+=1\n",
    "    return cnt\n",
    "\n",
    "def str_whole_word(str1, str2, i_):\n",
    "    cnt = 0\n",
    "    while i_ < len(str2):\n",
    "        i_ = str2.find(str1, i_)\n",
    "        if i_ == -1:\n",
    "            return cnt\n",
    "        else:\n",
    "            cnt += 1\n",
    "            i_ += len(str1)\n",
    "    return cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_all['query_in_title'] = df_all['product_info'].map(lambda x:str_whole_word(x.split('\\t')[0],x.split('\\t')[1],0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "df_all['query_in_description'] = df_all['product_info'].map(lambda x:str_whole_word(x.split('\\t')[0],x.split('\\t')[2],0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_all['product_info'] = df_all['search_term'].map(str)+\"\\t\"+df_all['product_title'].map(str) +\"\\t\"+df_all['product_description'].map(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "df_all['query_last_word_in_title'] = df_all['product_info'].map(lambda x:str_common_word(x.split('\\t')[0].split(\" \")[-1],x.split('\\t')[1]))\n",
    "\n",
    "df_all['word_in_title'] = df_all['product_info'].map(lambda x:str_common_word(x.split('\\t')[0],x.split('\\t')[1]))\n",
    "\n",
    "\n",
    "df_all['ratio_title'] = df_all['word_in_title']/df_all['len_of_query']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_all['query_last_word_in_description'] = df_all['product_info'].map(lambda x:str_common_word(x.split('\\t')[0].split(\" \")[-1],x.split('\\t')[2]))\n",
    "df_all['word_in_description'] = df_all['product_info'].map(lambda x:str_common_word(x.split('\\t')[0],x.split('\\t')[2]))\n",
    "df_all['ratio_description'] = df_all['word_in_description']/df_all['len_of_query']\n",
    "df_all['attr'] = df_all['search_term'].map(str)+\"\\t\"+df_all['brand'].map(str)\n",
    "df_all['word_in_brand'] = df_all['attr'].map(lambda x:str_common_word(x.split('\\t')[0],x.split('\\t')[1]))\n",
    "df_all['ratio_brand'] = df_all['word_in_brand']/df_all['len_of_brand']\n",
    "df_brand = pd.unique(df_all.brand.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "i = 1000\n",
    "d={}\n",
    "for s in df_brand:\n",
    "    d[s]=i\n",
    "    i+=3\n",
    "df_all['brand_feature'] = df_all['brand'].map(lambda x:d[x])\n",
    "df_all['search_term_feature'] = df_all['search_term'].map(lambda x:len(str(x)))\n",
    "df_all.to_csv('df_all.csv')\n",
    "#df_all = pd.read_csv('df_all.csv', encoding=\"ISO-8859-1\", index_col=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_train = df_all.iloc[:num_train]\n",
    "df_test = df_all.iloc[num_train:]\n",
    "id_test = df_test['id']\n",
    "y_train = df_train['relevance'].values\n",
    "X_train =df_train[:]\n",
    "X_test = df_test[:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>product_title</th>\n",
       "      <th>product_title_str</th>\n",
       "      <th>product_uid</th>\n",
       "      <th>relevance</th>\n",
       "      <th>search_term</th>\n",
       "      <th>search_term_num</th>\n",
       "      <th>search_term_str</th>\n",
       "      <th>product_description</th>\n",
       "      <th>product_description_num</th>\n",
       "      <th>...</th>\n",
       "      <th>query_last_word_in_description</th>\n",
       "      <th>word_in_title</th>\n",
       "      <th>word_in_description</th>\n",
       "      <th>ratio_title</th>\n",
       "      <th>ratio_description</th>\n",
       "      <th>attr</th>\n",
       "      <th>word_in_brand</th>\n",
       "      <th>ratio_brand</th>\n",
       "      <th>brand_feature</th>\n",
       "      <th>search_term_feature</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>100001</td>\n",
       "      <td>3</td>\n",
       "      <td>angl bracket</td>\n",
       "      <td>NaN</td>\n",
       "      <td>angl bracket</td>\n",
       "      <td>angl make joint stronger also provid consist s...</td>\n",
       "      <td>90.0 9.0 3.0 1.0 12.0 10.0 1.0 1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>angl bracket\\tsimpson strong-ti</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  product_title  product_title_str  product_uid  relevance   search_term  \\\n",
       "0   2              0                  0       100001          3  angl bracket   \n",
       "\n",
       "  search_term_num search_term_str  \\\n",
       "0             NaN    angl bracket   \n",
       "\n",
       "                                 product_description  \\\n",
       "0  angl make joint stronger also provid consist s...   \n",
       "\n",
       "              product_description_num         ...          \\\n",
       "0  90.0 9.0 3.0 1.0 12.0 10.0 1.0 1.0         ...           \n",
       "\n",
       "  query_last_word_in_description word_in_title  word_in_description  \\\n",
       "0                              0             0                    1   \n",
       "\n",
       "   ratio_title  ratio_description                             attr  \\\n",
       "0            0                0.5  angl bracket\\tsimpson strong-ti   \n",
       "\n",
       "   word_in_brand  ratio_brand  brand_feature search_term_feature  \n",
       "0              0            0           1000                  12  \n",
       "\n",
       "[1 rows x 31 columns]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def fmean_squared_error(ground_truth, predictions):\n",
    "    fmean_squared_error_ = mean_squared_error(ground_truth, predictions)**0.5\n",
    "    return fmean_squared_error_\n",
    "\n",
    "RMSE  = make_scorer(fmean_squared_error, greater_is_better=False)\n",
    "\n",
    "class cust_regression_vals(BaseEstimator, TransformerMixin):\n",
    "    def fit(self, x, y=None):\n",
    "        return self\n",
    "    def transform(self, hd_searches):\n",
    "        d_col_drops=['id','relevance','search_term','search_term_num','search_term_str','product_title',\n",
    "                     'product_title_str','product_description','product_description_num','product_description_str',\n",
    "                    'product_info','attr','brand']\n",
    "        #d_col_drops=['id','relevance','search_term','product_title','product_description','product_info','attr','brand']\n",
    "        hd_searches = hd_searches.drop(d_col_drops,axis=1).values\n",
    "        return hd_searches\n",
    "\n",
    "class cust_txt_col(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, key):\n",
    "        self.key = key\n",
    "    def fit(self, x, y=None):\n",
    "        return self\n",
    "    def transform(self, data_dict):\n",
    "        return data_dict[self.key].apply(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>product_title</th>\n",
       "      <th>product_title_str</th>\n",
       "      <th>product_uid</th>\n",
       "      <th>relevance</th>\n",
       "      <th>search_term</th>\n",
       "      <th>search_term_num</th>\n",
       "      <th>search_term_str</th>\n",
       "      <th>product_description</th>\n",
       "      <th>product_description_num</th>\n",
       "      <th>...</th>\n",
       "      <th>query_last_word_in_description</th>\n",
       "      <th>word_in_title</th>\n",
       "      <th>word_in_description</th>\n",
       "      <th>ratio_title</th>\n",
       "      <th>ratio_description</th>\n",
       "      <th>attr</th>\n",
       "      <th>word_in_brand</th>\n",
       "      <th>ratio_brand</th>\n",
       "      <th>brand_feature</th>\n",
       "      <th>search_term_feature</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>100001</td>\n",
       "      <td>3.00</td>\n",
       "      <td>angl bracket</td>\n",
       "      <td>0</td>\n",
       "      <td>angl bracket</td>\n",
       "      <td>angl make joint stronger also provid consist s...</td>\n",
       "      <td>90.0 9.0 3.0 1.0 12.0 10.0 1.0 1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>angl bracket\\tsimpson strong-ti</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1000</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>100001</td>\n",
       "      <td>2.50</td>\n",
       "      <td>l bracket</td>\n",
       "      <td>0</td>\n",
       "      <td>l bracket</td>\n",
       "      <td>angl make joint stronger also provid consist s...</td>\n",
       "      <td>90.0 9.0 3.0 1.0 12.0 10.0 1.0 1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>l bracket\\tsimpson strong-ti</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1000</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>100002</td>\n",
       "      <td>3.00</td>\n",
       "      <td>deck</td>\n",
       "      <td>0</td>\n",
       "      <td>deck</td>\n",
       "      <td>behr premium textur deckov innov solid color c...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>deck\\tbehr premium textur deckov</td>\n",
       "      <td>1</td>\n",
       "      <td>0.25</td>\n",
       "      <td>1003</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>100005</td>\n",
       "      <td>2.33</td>\n",
       "      <td>rain shower head</td>\n",
       "      <td>0</td>\n",
       "      <td>rain shower head</td>\n",
       "      <td>updat bathroom delta vero singl handl shower f...</td>\n",
       "      <td>3.0 10000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>rain shower head\\tdelta</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1006</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>100005</td>\n",
       "      <td>2.67</td>\n",
       "      <td>shower faucet</td>\n",
       "      <td>0</td>\n",
       "      <td>shower faucet</td>\n",
       "      <td>updat bathroom delta vero singl handl shower f...</td>\n",
       "      <td>3.0 10000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>shower faucet\\tdelta</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1006</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  product_title  product_title_str  product_uid  relevance  \\\n",
       "0   2              0                  0       100001       3.00   \n",
       "1   3              0                  0       100001       2.50   \n",
       "2   9              0                  0       100002       3.00   \n",
       "3  16              0                  0       100005       2.33   \n",
       "4  17              0                  0       100005       2.67   \n",
       "\n",
       "        search_term search_term_num   search_term_str  \\\n",
       "0      angl bracket               0      angl bracket   \n",
       "1         l bracket               0         l bracket   \n",
       "2              deck               0              deck   \n",
       "3  rain shower head               0  rain shower head   \n",
       "4     shower faucet               0     shower faucet   \n",
       "\n",
       "                                 product_description  \\\n",
       "0  angl make joint stronger also provid consist s...   \n",
       "1  angl make joint stronger also provid consist s...   \n",
       "2  behr premium textur deckov innov solid color c...   \n",
       "3  updat bathroom delta vero singl handl shower f...   \n",
       "4  updat bathroom delta vero singl handl shower f...   \n",
       "\n",
       "              product_description_num         ...          \\\n",
       "0  90.0 9.0 3.0 1.0 12.0 10.0 1.0 1.0         ...           \n",
       "1  90.0 9.0 3.0 1.0 12.0 10.0 1.0 1.0         ...           \n",
       "2                                 2.0         ...           \n",
       "3                         3.0 10000.0         ...           \n",
       "4                         3.0 10000.0         ...           \n",
       "\n",
       "  query_last_word_in_description word_in_title  word_in_description  \\\n",
       "0                              0             0                    1   \n",
       "1                              0             0                    1   \n",
       "2                              1             0                    1   \n",
       "3                              0             0                    1   \n",
       "4                              1             0                    2   \n",
       "\n",
       "   ratio_title  ratio_description                              attr  \\\n",
       "0            0           0.500000   angl bracket\\tsimpson strong-ti   \n",
       "1            0           0.500000      l bracket\\tsimpson strong-ti   \n",
       "2            0           1.000000  deck\\tbehr premium textur deckov   \n",
       "3            0           0.333333           rain shower head\\tdelta   \n",
       "4            0           1.000000              shower faucet\\tdelta   \n",
       "\n",
       "   word_in_brand  ratio_brand  brand_feature search_term_feature  \n",
       "0              0         0.00           1000                  12  \n",
       "1              0         0.00           1000                   9  \n",
       "2              1         0.25           1003                   4  \n",
       "3              0         0.00           1006                  16  \n",
       "4              0         0.00           1006                  13  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = X_train.fillna(0)\n",
    "X_train.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rfr = RandomForestRegressor(n_estimators = 500, n_jobs = 1, random_state = 2016, verbose = 1)\n",
    "tfidf = TfidfVectorizer(ngram_range=(1, 1),min_df=1)\n",
    "tsvd = TruncatedSVD(n_components=10, random_state = 2016)\n",
    "clf = pipeline.Pipeline([\n",
    "        ('union', FeatureUnion(\n",
    "                    transformer_list = [\n",
    "                        ('cst',  cust_regression_vals()),  \n",
    "                        ('txt1', pipeline.Pipeline([('s1', cust_txt_col(key='search_term')), ('tfidf1', tfidf), ('tsvd1', tsvd)])),\n",
    "                        ('txt2', pipeline.Pipeline([('s2', cust_txt_col(key='product_title')), ('tfidf2', tfidf), ('tsvd2', tsvd)])),\n",
    "                        ('txt3', pipeline.Pipeline([('s3', cust_txt_col(key='product_description')), ('tfidf3', tfidf), ('tsvd3', tsvd)])),\n",
    "                        ('txt4', pipeline.Pipeline([('s4', cust_txt_col(key='brand')), ('tfidf4', tfidf), ('tsvd4', tsvd)]))\n",
    "                        ],\n",
    "                    transformer_weights = {\n",
    "                        'cst': 1.0,\n",
    "                        'txt1': 0.5,\n",
    "                        'txt2': 0.25,\n",
    "                        'txt3': 0.0,\n",
    "                        'txt4': 0.5\n",
    "                        },\n",
    "                #n_jobs = -1\n",
    "                )), \n",
    "        ('rfr', svr_rbf)])\n",
    "param_grid = {'rfr__max_features': [10], 'rfr__max_depth': [20]}\n",
    "model = grid_search.GridSearchCV(estimator = clf, param_grid = param_grid, n_jobs = 1, cv = 2, verbose = 20, scoring=RMSE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 1 candidates, totalling 2 fits\n",
      "[CV] rfr__max_depth=20, rfr__max_features=10 .........................\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Invalid parameter max_depth for estimator SVR",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-163-35a8e67277e9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\Users\\sneha\\Anaconda324\\lib\\site-packages\\sklearn\\grid_search.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    730\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    731\u001b[0m         \"\"\"\n\u001b[1;32m--> 732\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mParameterGrid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    733\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    734\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\sneha\\Anaconda324\\lib\\site-packages\\sklearn\\grid_search.py\u001b[0m in \u001b[0;36m_fit\u001b[1;34m(self, X, y, parameter_iterable)\u001b[0m\n\u001b[0;32m    503\u001b[0m                                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreturn_parameters\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    504\u001b[0m                                     error_score=self.error_score)\n\u001b[1;32m--> 505\u001b[1;33m                 \u001b[1;32mfor\u001b[0m \u001b[0mparameters\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mparameter_iterable\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    506\u001b[0m                 for train, test in cv)\n\u001b[0;32m    507\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\sneha\\Anaconda324\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m    657\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    658\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mfunction\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 659\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunction\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    660\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    661\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mpre_dispatch\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"all\"\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mn_jobs\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\sneha\\Anaconda324\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36mdispatch\u001b[1;34m(self, func, args, kwargs)\u001b[0m\n\u001b[0;32m    404\u001b[0m         \"\"\"\n\u001b[0;32m    405\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_pool\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 406\u001b[1;33m             \u001b[0mjob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImmediateApply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    407\u001b[0m             \u001b[0mindex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    408\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0m_verbosity_filter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\sneha\\Anaconda324\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, func, args, kwargs)\u001b[0m\n\u001b[0;32m    138\u001b[0m         \u001b[1;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    139\u001b[0m         \u001b[1;31m# arguments in memory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 140\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    141\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    142\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\sneha\\Anaconda324\\lib\\site-packages\\sklearn\\cross_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[1;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, error_score)\u001b[0m\n\u001b[0;32m   1446\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1447\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mparameters\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1448\u001b[1;33m         \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_params\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1449\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1450\u001b[0m     \u001b[0mstart_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\sneha\\Anaconda324\\lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36mset_params\u001b[1;34m(self, **params)\u001b[0m\n\u001b[0;32m    249\u001b[0m                                      (name, self))\n\u001b[0;32m    250\u001b[0m                 \u001b[0msub_object\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvalid_params\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 251\u001b[1;33m                 \u001b[0msub_object\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_params\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0msub_name\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    252\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    253\u001b[0m                 \u001b[1;31m# simple objects case\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\sneha\\Anaconda324\\lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36mset_params\u001b[1;34m(self, **params)\u001b[0m\n\u001b[0;32m    254\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mkey\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mvalid_params\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    255\u001b[0m                     raise ValueError('Invalid parameter %s ' 'for estimator %s'\n\u001b[1;32m--> 256\u001b[1;33m                                      % (key, self.__class__.__name__))\n\u001b[0m\u001b[0;32m    257\u001b[0m                 \u001b[0msetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    258\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Invalid parameter max_depth for estimator SVR"
     ]
    }
   ],
   "source": [
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters found by grid search:\n",
      "{'rfr__max_depth': 20, 'rfr__max_features': 10}\n",
      "Best CV score:\n",
      "-0.47016679181\n",
      "-0.000134799069826\n"
     ]
    }
   ],
   "source": [
    "print(\"Best parameters found by grid search:\")\n",
    "print(model.best_params_)\n",
    "print(\"Best CV score:\")\n",
    "print(model.best_score_)\n",
    "print(model.best_score_ + 0.47003199274)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 jobs       | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  50 jobs       | elapsed:    1.1s\n",
      "[Parallel(n_jobs=1)]: Done 200 jobs       | elapsed:    4.7s\n",
      "[Parallel(n_jobs=1)]: Done 450 jobs       | elapsed:   10.8s\n",
      "[Parallel(n_jobs=1)]: Done 500 out of 500 | elapsed:   12.1s finished\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "pd.DataFrame({\"id\": id_test, \"relevance\": y_pred}).to_csv('submission_tfidf2.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method BaseEstimator.get_params of GridSearchCV(cv=2, error_score='raise',\n",
       "       estimator=Pipeline(steps=[('union', FeatureUnion(n_jobs=1,\n",
       "       transformer_list=[('cst', cust_regression_vals()), ('txt1', Pipeline(steps=[('s1', cust_txt_col(key='search_term')), ('tfidf1', TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', ...imators=500, n_jobs=1, oob_score=False, random_state=2016,\n",
       "           verbose=1, warm_start=False))]),\n",
       "       fit_params={}, iid=True, loss_func=None, n_jobs=1,\n",
       "       param_grid={'rfr__max_depth': [20], 'rfr__max_features': [10]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, score_func=None,\n",
       "       scoring=make_scorer(fmean_squared_error, greater_is_better=False),\n",
       "       verbose=20)>"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.grid_scores_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import SVR\n",
    "svr_rbf = SVR(kernel='rbf', C=1e3, gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1\n",
       "1    1\n",
       "2    1\n",
       "3    1\n",
       "4    2\n",
       "Name: product_info, dtype: int64"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all['product_info'].head(5).map(lambda x:str_common_word(x.split('\\t')[0],x.split('\\t')[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "df_all['ratio_title'] = df_all['word_in_title']/df_all['len_of_query']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
